{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoMj8iGaa4w3"
      },
      "source": [
        "# ü©ª NeuroScan Pro: Multi-Model Anomaly Detection\n",
        "\n",
        "This notebook sets up and runs the **NeuroScan Pro** environment. It uses **Generative AI (VAE, GAN, ViT)** to detect medical anomalies (Pneumonia) using Unsupervised Learning.\n",
        "\n",
        "### üöÄ Instructions\n",
        "1. **Run All Cells** to generate the necessary python files.\n",
        "2. Ensure you have the **Chest X-Ray Dataset** (Normal/Pneumonia) ready.\n",
        "3. The final cell will launch the **Streamlit Dashboard**."
      ],
      "id": "FoMj8iGaa4w3"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bnIeB2C8a4xA",
        "outputId": "9b261cf3-0cd1-4f43-d148-79f1af923293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.53.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=5.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.6)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Downloading streamlit-1.53.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.53.1\n"
          ]
        }
      ],
      "source": [
        "# 1. Install Dependencies\n",
        "!pip install torch torchvision streamlit matplotlib seaborn pandas scikit-learn"
      ],
      "id": "bnIeB2C8a4xA"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w12z6Q_da4xE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Create directory for saved models\n",
        "if not os.path.exists('saved_models'):\n",
        "    os.makedirs('saved_models')"
      ],
      "id": "w12z6Q_da4xE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWGfJihva4xH"
      },
      "source": [
        "## üõ†Ô∏è Step 1: Define Model Architectures (`model.py`)"
      ],
      "id": "MWGfJihva4xH"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DSlzRxma4xK",
        "outputId": "ca76a1e5-bd58-48b5-8c3c-a4a2b279d93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ==========================================\n",
        "# 1. VAE (Variational Autoencoder)\n",
        "# ==========================================\n",
        "class MedicalVAE(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super(MedicalVAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
        "            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(),\n",
        "            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(16384, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(16384, latent_dim)\n",
        "        self.decoder_input = nn.Linear(latent_dim, 16384)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Unflatten(1, (256, 8, 8)),\n",
        "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1), nn.BatchNorm2d(128), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 3, 2, 1, 1), nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, 3, 2, 1, 1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = self.fc_mu(h), self.fc_logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        z_proj = self.decoder_input(z)\n",
        "        return self.decoder(z_proj), mu, logvar\n",
        "\n",
        "def vae_loss_function(recon_x, x, mu, logvar):\n",
        "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kld_loss\n",
        "\n",
        "# ==========================================\n",
        "# 2. GAN (Generative Adversarial Network)\n",
        "# ==========================================\n",
        "class MedicalGANGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super(MedicalGANGenerator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 2, 1), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32768, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 32768),\n",
        "            nn.Unflatten(1, (128, 16, 16)),\n",
        "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 3, 2, 1, 1), nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, 3, 2, 1, 1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)\n",
        "\n",
        "class MedicalGANDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MedicalGANDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, 2, 1), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(16, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16384, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ==========================================\n",
        "# 3. Vision Transformer (ViT-AE)\n",
        "# ==========================================\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, img_size=128, patch_size=16, in_channels=1, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class MedicalTransformer(nn.Module):\n",
        "    def __init__(self, img_size=128, patch_size=16, embed_dim=128, depth=4, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbedding(img_size, patch_size, 1, embed_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
        "        self.decoder_proj = nn.Linear(embed_dim, patch_size*patch_size)\n",
        "        self.patch_size = patch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        patches = self.patch_embed(x)\n",
        "        encoded = self.transformer_encoder(patches)\n",
        "        rec_patches = self.decoder_proj(encoded)\n",
        "        rec_patches = rec_patches.transpose(1, 2)\n",
        "        rec_img = F.fold(rec_patches, output_size=(H, W), kernel_size=self.patch_size, stride=self.patch_size)\n",
        "        return torch.sigmoid(rec_img)"
      ],
      "id": "9DSlzRxma4xK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWBfrb7va4xO"
      },
      "source": [
        "## üß™ Step 2: Define Utils (`utils.py`)"
      ],
      "id": "BWBfrb7va4xO"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zdUFxzva4xP",
        "outputId": "c6cbc585-cf4a-43f2-d13c-34018966b858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def calculate_metrics(model, test_loader, threshold_percentile=95):\n",
        "    model.eval()\n",
        "    errors = []\n",
        "    labels = []\n",
        "    criterion = torch.nn.MSELoss(reduction='none')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, label in test_loader:\n",
        "            data = data.to(next(model.parameters()).device)\n",
        "            if hasattr(model, 'reparameterize'):\n",
        "                recon, _, _ = model(data)\n",
        "            else:\n",
        "                recon = model(data)\n",
        "            loss = criterion(recon, data).mean(dim=[1, 2, 3])\n",
        "            errors.extend(loss.cpu().numpy())\n",
        "            labels.extend(label.numpy())\n",
        "\n",
        "    threshold = np.percentile(errors, threshold_percentile)\n",
        "    preds = [1 if e > threshold else 0 for e in errors]\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average='binary')\n",
        "    return acc, f1\n",
        "\n",
        "def plot_comparison(original, recons, titles):\n",
        "    num_models = len(recons)\n",
        "    cols = num_models + 1\n",
        "    rows = 2\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 8))\n",
        "\n",
        "    if num_models == 0: return fig\n",
        "    if len(axes.shape) == 1: axes = axes.reshape(rows, cols)\n",
        "\n",
        "    orig_np = original.squeeze().cpu().detach().numpy()\n",
        "\n",
        "    # Row 1: Reconstruction\n",
        "    axes[0, 0].imshow(orig_np, cmap='gray')\n",
        "    axes[0, 0].set_title(\"Original Input\", fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    for i, (recon, title) in enumerate(zip(recons, titles)):\n",
        "        recon_np = recon.squeeze().cpu().detach().numpy()\n",
        "        axes[0, i+1].imshow(recon_np, cmap='gray')\n",
        "        axes[0, i+1].set_title(f\"{title}\\n(Reconstruction)\", fontsize=12)\n",
        "        axes[0, i+1].axis('off')\n",
        "\n",
        "    # Row 2: Anomaly Map\n",
        "    axes[1, 0].text(0.5, 0.5, \"Difference Maps\\n(Anomaly Detection)\",\n",
        "                    ha='center', va='center', fontsize=12)\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    for i, (recon, title) in enumerate(zip(recons, titles)):\n",
        "        recon_np = recon.squeeze().cpu().detach().numpy()\n",
        "        diff_np = np.abs(orig_np - recon_np)\n",
        "        im = axes[1, i+1].imshow(diff_np, cmap='inferno', vmin=0, vmax=1)\n",
        "        axes[1, i+1].set_title(f\"{title}\\n(Anomaly Map)\", fontsize=12, color='red')\n",
        "        axes[1, i+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "id": "1zdUFxzva4xP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBaaQl90a4xR"
      },
      "source": [
        "## üñ•Ô∏è Step 3: Define Streamlit Application (`app.py`)\n",
        "This file contains the UI logic, Tab structure, and Session State management."
      ],
      "id": "EBaaQl90a4xR"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tBjCWbea4xV",
        "outputId": "25cf9c44-632f-4767-e237-53f9493f881b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model import MedicalVAE, MedicalGANGenerator, MedicalGANDiscriminator, MedicalTransformer, vae_loss_function\n",
        "from utils import plot_comparison, calculate_metrics\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "MODEL_DIR = \"saved_models\"\n",
        "\n",
        "if not os.path.exists(MODEL_DIR): os.makedirs(MODEL_DIR)\n",
        "\n",
        "st.set_page_config(page_title=\"NeuroScan Pro\", layout=\"wide\", page_icon=\"ü©ª\")\n",
        "st.title=\"ü©ª NeuroScan Pro: Multi-Model Anomaly Detection\"\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state['history'] = {'VAE': [], 'GAN': [], 'ViT': []}\n",
        "\n",
        "if 'leaderboard' not in st.session_state:\n",
        "    st.session_state['leaderboard'] = []\n",
        "\n",
        "if 'benchmark_data' not in st.session_state:\n",
        "    st.session_state['benchmark_data'] = None\n",
        "\n",
        "if 'dataset_path' not in st.session_state:\n",
        "    st.session_state['dataset_path'] = os.path.join(os.getcwd(), \"chest_xray\")\n",
        "\n",
        "def pick_folder():\n",
        "    try:\n",
        "        root = tk.Tk()\n",
        "        root.withdraw()\n",
        "        root.wm_attributes('-topmost', 1)\n",
        "        folder_path = filedialog.askdirectory(master=root)\n",
        "        root.destroy()\n",
        "        return folder_path\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def get_data_loaders(root_dir, mode='train'):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    if not os.path.exists(root_dir): return None, None\n",
        "    dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
        "    if mode == 'train':\n",
        "        idx = [i for i, label in enumerate(dataset.targets) if dataset.classes[label] == 'NORMAL']\n",
        "        subset = Subset(dataset, idx)\n",
        "        return DataLoader(subset, batch_size=BATCH_SIZE, shuffle=True), dataset.classes\n",
        "    else:\n",
        "        return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False), dataset\n",
        "\n",
        "def save_model(model, name):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
        "    path = os.path.join(MODEL_DIR, f\"{name}_{timestamp}.pt\")\n",
        "    torch.save(model.state_dict(), path)\n",
        "    return path\n",
        "\n",
        "st.sidebar.header=\"üìÇ Data & Config\"\n",
        "c1, c2 = st.sidebar.columns([3, 1])\n",
        "with c2:\n",
        "    if st.button(\"üìÇ\"):\n",
        "        fp = pick_folder()\n",
        "        if fp: st.session_state['dataset_path'] = fp\n",
        "with c1:\n",
        "    dataset_path = st.text_input(\"Dataset Path\", value=st.session_state['dataset_path'])\n",
        "\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "test_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "tab1, tab2 = st.tabs([\"üöÄ Training & Metrics\", \"üîé Comparative Diagnostics\"])\n",
        "\n",
        "with tab1:\n",
        "    col_ctrl, col_metrics = st.columns([2, 1])\n",
        "    with col_ctrl:\n",
        "        st.header(\"1. Train New Model\")\n",
        "        model_type = st.selectbox(\"Select Model Architecture\", [\"VAE\", \"GAN\", \"Transformer (ViT)\", \"Train ALL Sequentially\"])\n",
        "        epochs = st.slider(\"Epochs\", 1, 50, 10)\n",
        "        lr = st.selectbox(\"Learning Rate\", [1e-3, 1e-4, 2e-4])\n",
        "        start_btn = st.button(\"Start Training\")\n",
        "\n",
        "    with col_metrics:\n",
        "        st.subheader(\"üèÜ Live Leaderboard\")\n",
        "        if st.session_state['leaderboard']:\n",
        "            st.dataframe(pd.DataFrame(st.session_state['leaderboard']))\n",
        "            if st.button(\"Clear Leaderboard\"):\n",
        "                st.session_state['leaderboard'] = []\n",
        "                st.rerun()\n",
        "        else:\n",
        "            st.info(\"Train a model to see metrics here.\")\n",
        "\n",
        "    if start_btn:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        loader, _ = get_data_loaders(train_path, mode='train')\n",
        "        test_loader, _ = get_data_loaders(test_path, mode='test')\n",
        "        if not loader:\n",
        "            st.error(\"Could not load training data. Check path.\")\n",
        "            st.stop()\n",
        "\n",
        "        models_to_train = [\"VAE\", \"GAN\", \"ViT\"] if model_type == \"Train ALL Sequentially\" else [model_type.split()[0]]\n",
        "        progress_bar = st.progress(0)\n",
        "\n",
        "        for m_name in models_to_train:\n",
        "            st.subheader(f\"Training {m_name}...\")\n",
        "            if m_name == \"VAE\":\n",
        "                model = MedicalVAE().to(device)\n",
        "                opt = optim.Adam(model.parameters(), lr=lr)\n",
        "            elif m_name == \"GAN\":\n",
        "                gen = MedicalGANGenerator().to(device)\n",
        "                disc = MedicalGANDiscriminator().to(device)\n",
        "                opt_g = optim.Adam(gen.parameters(), lr=lr)\n",
        "                opt_d = optim.Adam(disc.parameters(), lr=lr)\n",
        "                criterion = nn.BCELoss()\n",
        "                model = gen\n",
        "            elif m_name in [\"Transformer\", \"ViT\"]:\n",
        "                model = MedicalTransformer().to(device)\n",
        "                opt = optim.Adam(model.parameters(), lr=lr)\n",
        "                criterion = nn.MSELoss()\n",
        "\n",
        "            params = count_parameters(model)\n",
        "            st.info(f\"üß† **{m_name} Parameters:** {params:,}\")\n",
        "            history = []\n",
        "            for epoch in range(epochs):\n",
        "                epoch_loss = 0\n",
        "                for x, _ in loader:\n",
        "                    x = x.to(device)\n",
        "                    if m_name == \"VAE\":\n",
        "                        opt.zero_grad()\n",
        "                        recon, mu, logvar = model(x)\n",
        "                        loss = vae_loss_function(recon, x, mu, logvar)\n",
        "                        loss.backward()\n",
        "                        opt.step()\n",
        "                        epoch_loss += loss.item()\n",
        "                    elif m_name == \"GAN\":\n",
        "                        opt_d.zero_grad()\n",
        "                        real_labels = torch.ones(x.size(0), 1).to(device)\n",
        "                        fake_labels = torch.zeros(x.size(0), 1).to(device)\n",
        "                        d_real = disc(x)\n",
        "                        d_loss_real = criterion(d_real, real_labels)\n",
        "                        fake_img = gen(x)\n",
        "                        d_fake = disc(fake_img.detach())\n",
        "                        d_loss_fake = criterion(d_fake, fake_labels)\n",
        "                        d_loss = d_loss_real + d_loss_fake\n",
        "                        d_loss.backward()\n",
        "                        opt_d.step()\n",
        "                        opt_g.zero_grad()\n",
        "                        d_fake_preds = disc(fake_img)\n",
        "                        g_adv_loss = criterion(d_fake_preds, real_labels)\n",
        "                        g_pixel_loss = F.mse_loss(fake_img, x)\n",
        "                        g_loss = g_adv_loss + (100 * g_pixel_loss)\n",
        "                        g_loss.backward()\n",
        "                        opt_g.step()\n",
        "                        epoch_loss += g_loss.item()\n",
        "                    elif m_name in [\"Transformer\", \"ViT\"]:\n",
        "                        opt.zero_grad()\n",
        "                        recon = model(x)\n",
        "                        loss = criterion(recon, x)\n",
        "                        loss.backward()\n",
        "                        opt.step()\n",
        "                        epoch_loss += loss.item()\n",
        "                avg_loss = epoch_loss / len(loader)\n",
        "                history.append(avg_loss)\n",
        "                progress_bar.progress((epoch + 1) / epochs)\n",
        "            st.session_state['history'][m_name] = history\n",
        "            if m_name == \"GAN\": save_model(gen.cpu(), \"GAN\")\n",
        "            else: save_model(model.cpu(), m_name)\n",
        "            model.cpu()\n",
        "            acc, f1 = calculate_metrics(model, test_loader)\n",
        "            st.session_state['leaderboard'].append({\n",
        "                \"Model\": m_name,\n",
        "                \"Accuracy\": f\"{acc:.2%}\",\n",
        "                \"F1 Score\": f\"{f1:.3f}\",\n",
        "                \"Params\": f\"{params:,}\",\n",
        "                \"Timestamp\": datetime.now().strftime(\"%H:%M\")\n",
        "            })\n",
        "            st.success(f\"‚úÖ {m_name} Trained & Saved!\")\n",
        "\n",
        "    st.divider()\n",
        "    st.subheader(\"Training Performance (Logarithmic Scale)\")\n",
        "    if any(st.session_state['history'].values()):\n",
        "        fig, ax = plt.subplots()\n",
        "        for name, hist in st.session_state['history'].items():\n",
        "            if hist: ax.plot(hist, label=f\"{name} Loss\")\n",
        "        ax.set_xlabel(\"Epochs\")\n",
        "        ax.set_ylabel(\"Loss (Log Scale)\")\n",
        "        ax.set_yscale('log')\n",
        "        ax.legend()\n",
        "        ax.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Comparative Diagnostics\")\n",
        "    saved_files = sorted(glob.glob(os.path.join(MODEL_DIR, \"*.ptÊñá\")), reverse=True)\n",
        "    c1, c2, c3 = st.columns(3)\n",
        "    vae_file = c1.selectbox(\"Load VAE\", [f for f in saved_files if \"VAE\" in f] + [\"None\"])\n",
        "    gan_file = c2.selectbox(\"Load GAN\", [f for f in saved_files if \"GAN\" in f] + [\"None\"])\n",
        "    vit_file = c3.selectbox(\"Load ViT\", [f for f in saved_files if \"Transformer\" in f or \"ViT\" in f] + [\"None\"])\n",
        "    st.divider()\n",
        "\n",
        "    def load_selected_models():\n",
        "        models = {}\n",
        "        if vae_file != \"None\":\n",
        "            m = MedicalVAE()\n",
        "            m.load_state_dict(torch.load(vae_file, map_location='cpu'))\n",
        "            models['VAE'] = m\n",
        "        if gan_file != \"None\":\n",
        "            m = MedicalGANGenerator()\n",
        "            m.load_state_dict(torch.load(gan_file, map_location='cpu'))\n",
        "            models['GAN'] = m\n",
        "        if vit_file != \"None\":\n",
        "            m = MedicalTransformer()\n",
        "            m.load_state_dict(torch.load(vit_file, map_location='cpu'))\n",
        "            models['ViT'] = m\n",
        "        return models\n",
        "\n",
        "    st.subheader(\"1. Model Performance Benchmark\")\n",
        "    if st.button(\"üìä Run Performance Benchmark\", use_container_width=True):\n",
        "        models = load_selected_models()\n",
        "        if not models:\n",
        "            st.error(\"Please load at least one model.\")\n",
        "        else:\n",
        "            test_loader, _ = get_data_loaders(test_path, mode='test')\n",
        "            with st.spinner(\"Calculating Metrics...\"):\n",
        "                metrics_data = []\n",
        "                for name, model in models.items():\n",
        "                    acc, f1 = calculate_metrics(model, test_loader)\n",
        "                    params = count_parameters(model)\n",
        "                    metrics_data.append({\"Model\": name, \"Accuracy\": f\"{acc:.2%}\", \"F1 Score\": f\"{f1:.3f}\", \"Parameters\": f\"{params:,}\"})\n",
        "                st.session_state['benchmark_data'] = pd.DataFrame(metrics_data)\n",
        "\n",
        "    if st.session_state['benchmark_data'] is not None:\n",
        "        st.table(st.session_state['benchmark_data'])\n",
        "        if st.button(\"Clear Table\"):\n",
        "            st.session_state['benchmark_data'] = None\n",
        "            st.rerun()\n",
        "\n",
        "    st.divider()\n",
        "    st.subheader(\"2. Visual Reconstruction Inspection\")\n",
        "    if st.button(\"üëÅÔ∏è Run Visual Inspection (Random Batch)\", use_container_width=True):\n",
        "        models = load_selected_models()\n",
        "        if not models:\n",
        "            st.error(\"Please load at least one model.\")\n",
        "        else:\n",
        "            _, full_test_dataset = get_data_loaders(test_path, mode='test')\n",
        "            def get_random_image(target_label_name):\n",
        "                target_idx = full_test_dataset.class_to_idx[target_label_name]\n",
        "                indices = [i for i, label in enumerate(full_test_dataset.targets) if label == target_idx]\n",
        "                rand_idx = np.random.choice(indices)\n",
        "                img, _ = full_test_dataset[rand_idx]\n",
        "                return img.unsqueeze(0)\n",
        "\n",
        "            col_normal, col_pneumonia = st.columns(2)\n",
        "            with col_normal:\n",
        "                st.info(\"üü¢ **Control Case: NORMAL**\")\n",
        "                img_normal = get_random_image(\"NORMAL\")\n",
        "                recons_n = []\n",
        "                titles_n = []\n",
        "                for name, model in models.items():\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        recon = model(img_normal) if name != \"VAE\" else model(img_normal)[0]\n",
        "                    recons_n.append(recon)\n",
        "                    titles_n.append(name)\n",
        "                fig_n = plot_comparison(img_normal, recons_n, titles_n)\n",
        "                st.pyplot(fig_n)\n",
        "\n",
        "            with col_pneumonia:\n",
        "                st.error(\"üî¥ **Test Case: PNEUMONIA**\")\n",
        "                img_pneu = get_random_image(\"PNEUMONIA\")\n",
        "                recons_p = []\n",
        "                titles_p = []\n",
        "                for name, model in models.items():\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        recon = model(img_pneu) if name != \"VAE\" else model(img_pneu)[0]\n",
        "                    recons_p.append(recon)\n",
        "                    titles_p.append(name)\n",
        "                fig_p = plot_comparison(img_pneu, recons_p, titles_p)\n",
        "                st.pyplot(fig_p)\n",
        "            st.caption(\"Each click loads a new random set of images.\")"
      ],
      "id": "4tBjCWbea4xV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4pt8UxBa4xc"
      },
      "source": [
        "## üöÄ Step 4: Run the Dashboard\n",
        "Run the following command to start the app. It will provide a local URL."
      ],
      "id": "v4pt8UxBa4xc"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaSav0y7a4xe",
        "outputId": "7d1bc508-3bed-4298-90c2-267f2a983b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0KPassword/Endpoint IP for localtunnel is: 35.187.239.97\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "your url is: https://angry-insects-mate.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.187.239.97:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# 1. Install localtunnel\n",
        "!npm install localtunnel\n",
        "\n",
        "# 2. Get the Password (IP Address)\n",
        "# IMPORTANT: You will need to enter this IP on the website that opens.\n",
        "import urllib\n",
        "print(\"Password/Endpoint IP for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "\n",
        "# 3. Run Streamlit in the background & Expose it\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "id": "VaSav0y7a4xe"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}